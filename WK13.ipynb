{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WK13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnp/ao5wER0cHGLbitdrwg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pittella0/HomeWork/blob/main/WK13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is accuracy, precision, and recall?"
      ],
      "metadata": {
        "id": "qNiMYGI_VPfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: Accuracy is a measure that determines how many observations are predicted correctly.\n",
        "\n",
        "Accuracy = (True Positive + True Negative) / (True Positive + True Negative + False Positive + False Negative)\n",
        "\n"
      ],
      "metadata": {
        "id": "obmgvePSVZ07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision: Precision is a measure that determines how many observations that are marked as positive are actually positive.\n",
        "\n",
        "Precision = True Positive / (True Positive + False Positive)\n",
        "\n"
      ],
      "metadata": {
        "id": "cx1Aye2xVg_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Recall: Recall is also known as sensitivity. It is a measure that determines how many positive observations were actually classified as positive.\n",
        "\n",
        "Recall = True Positive / (True Positive + False Negative)\n"
      ],
      "metadata": {
        "id": "WDgB7NDsVkYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What is a confusion matrix?"
      ],
      "metadata": {
        "id": "FZAr_W6iWZUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model.\n"
      ],
      "metadata": {
        "id": "Cn5IWPrZWdB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "True Positive (TP) \n",
        "\n",
        "The predicted value matches the actual value\n",
        "The actual value was positive and the model predicted a positive value"
      ],
      "metadata": {
        "id": "kZC0NbzNWyTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "True Negative (TN) \n",
        "\n",
        "The predicted value matches the actual value\n",
        "The actual value was negative and the model predicted a negative value"
      ],
      "metadata": {
        "id": "qiD5njLeWzI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "False Positive (FP) – Type 1 error\n",
        "\n",
        "The predicted value was falsely predicted\n",
        "The actual value was negative but the model predicted a positive value\n",
        "Also known as the Type 1 error"
      ],
      "metadata": {
        "id": "__UKsfy8W46m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "False Negative (FN) – Type 2 error\n",
        "\n",
        "The predicted value was falsely predicted\n",
        "The actual value was positive but the model predicted a negative value\n",
        "Also known as the Type 2 error"
      ],
      "metadata": {
        "id": "mt7GJiJhW7Tu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fRrYQn4In5yg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbc17ea-cfee-4345-c279-1b780c99460c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation :  [1, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
            "Prediction  :  [1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
            "TP =  4\n",
            "TN =  3\n",
            "FP =  2\n",
            "FN =  1\n",
            "Accuracy : 70.00\n",
            "Precision : 66.67\n",
            "Recall : 80.00\n",
            "F1 Score : 72.73\n"
          ]
        }
      ],
      "source": [
        "Observation = [1, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
        "Prediction = [1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
        "\n",
        "# TP is the count of true positive cases\n",
        "TP = 0\n",
        "# TN is the count of true negative cases\n",
        "TN = 0\n",
        "# FP is the count of false positive cases\n",
        "FP = 0\n",
        "# FN is the count of false negative cases\n",
        "FN = 0\n",
        "\n",
        "\"\"\"\n",
        "for-loop is used to iterate through the observation and prediction array\n",
        "each observation and corresponding prediction is compared within the loop\n",
        "to identify TP, TN, FP and FN\n",
        "at the end of the loop, total number of TP, TN, FP and FN is available\n",
        "\"\"\"\n",
        "for i in range(0,len(Observation)):\n",
        "    if Observation[i] == 1 and Prediction[i] == 1:\n",
        "       TP = TP + 1\n",
        "    if Observation[i] == 0 and Prediction[i] == 0:\n",
        "       TN = TN + 1\n",
        "    if Observation[i] == 0 and Prediction[i] == 1:\n",
        "       FP = FP + 1\n",
        "    if Observation[i] == 1 and Prediction[i] == 0:\n",
        "       FN = FN + 1\n",
        "\n",
        "print(\"Observation : \", Observation)\n",
        "print(\"Prediction  : \", Prediction)\n",
        "\n",
        "# print the counts \n",
        "print(\"TP = \", TP)\n",
        "print(\"TN = \", TN)\n",
        "print(\"FP = \", FP)\n",
        "print(\"FN = \", FN)\n",
        "\n",
        "# Accuracy = (True Positive + True Negative) / (True Positive + True \n",
        "# Negative + False Positive + False Negative)\n",
        "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "\n",
        "# Precision = True Positive / (True Positive + False Positive)\n",
        "Precision = TP / (TP + FP)\n",
        "\n",
        "# Recall = True Positive / (True Positive + False Negative)\n",
        "Recall = TP / (TP + FN)\n",
        "\n",
        "#F1-score = 2 * ((Precision * Recall) / (Precision + Recall))\n",
        "F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "# print is used with appropriate formatting to print upto 2 digits after \n",
        "# the decimal places\n",
        "\n",
        "\n",
        "print(f\"Accuracy : {Accuracy*100:.2f}\")\n",
        "print(f\"Precision : {Precision*100:.2f}\")\n",
        "\n",
        "print(f\"Recall : {Recall*100:.2f}\")\n",
        "\n",
        "print(f\"F1 Score : {F1*100:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Type 1 and Type 2 errors"
      ],
      "metadata": {
        "id": "9y3dXvyskpB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type 1 is a false positive\n",
        "\n",
        "which means you think you do, but you dont"
      ],
      "metadata": {
        "id": "-dKRDCQwktwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type 2 is false negative\n",
        "\n",
        "which mean you think you dont, but you do"
      ],
      "metadata": {
        "id": "uKccRZ7QkzSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What is train.test split()"
      ],
      "metadata": {
        "id": "-YXtE2sBeYXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train-test split is a technique for evaluating the performance of a machine learning algorithm. It can be used for classification or regression problems and can be used for any supervised learning algorithm. The procedure involves taking a dataset and dividing it into two subsets."
      ],
      "metadata": {
        "id": "htp8sjBjecBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first subset is used to fit the model and is referred to as the training dataset.\n"
      ],
      "metadata": {
        "id": "RBqFZ6--gIPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "p_JmRzS5gPMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What is the bias vs. variance tradeoff?"
      ],
      "metadata": {
        "id": "AHY-qfIvhpCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bias is the simplifying assumptions made by the model to make the target function easier to approximate."
      ],
      "metadata": {
        "id": "C3z1FE3Chqm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variance is the amount that the estimate of the target function will change given different training data."
      ],
      "metadata": {
        "id": "BUYm1BwhikZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trade-off is tension between the error introduced by the bias and the variance.\n"
      ],
      "metadata": {
        "id": "0c_fjhJjipH5"
      }
    }
  ]
}